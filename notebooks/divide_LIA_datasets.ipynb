{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1469fbfb",
   "metadata": {},
   "source": [
    "# LIA subsets\n",
    "\n",
    "LIA was divided into train, dev and test in [UD](https://github.com/UniversalDependencies/UD_Norwegian-NynorskLIA/tree/8a4ea1a6e0e1fbb4ef5ba34c2d408563e9c8cf9a).\n",
    "\n",
    "The [LIA](https://github.com/textlab/spoken_norwegian_resources/tree/master/treebanks/Norwegian-NynorskLIA) conllu-treebank is divided into 18 files, 1 per speaker/conversation.\n",
    "\n",
    "Each sentence has a unique `sent_id` across all partitions in UD, as opposed to LIA where each sentence is given a file-internal `id` which is incremental from 1 in each file. \n",
    "\n",
    "Here we map the speaker/file-id from UD + sent_id back to LIA to recreate the partitions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55150fa3",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import conllu\n",
    "from conllu import parse\n",
    "\n",
    "UD_path = Path(\"../data/UD_Norwegian-NynorskLIA\")\n",
    "LIA_path = Path(\"../spoken_norwegian_resources/treebanks/Norwegian-NynorskLIA\")\n",
    "LIA_old_path = Path(\"../spoken_norwegian_resources/treebanks/Norwegian-NynorskLIA_old\")\n",
    "\n",
    "\n",
    "def load_partition(filepath: Path, partition: str = \"train\") -> list:\n",
    "    \"\"\"Load one of the UD dataset partitions train, dev, or test.\"\"\"\n",
    "    data = next(filepath.glob(f\"*{partition}.conllu\")).read_text()\n",
    "    sentences = parse(\n",
    "        data,\n",
    "        metadata_parsers={\n",
    "            \"sent_id\": lambda key, value: (key, value),\n",
    "            \"text\": lambda key, value: (key, value),\n",
    "            \"__fallback__\": lambda key, value: [\n",
    "                [k.rstrip(\":\"), key.split()[i + 1]]\n",
    "                for i, k in list(enumerate(key.split()))[::2]\n",
    "            ],\n",
    "        },\n",
    "    )\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def load_lia_sentences(\n",
    "    filestem: str, dir_path: Path = Path(\"../spoken_norwegian_resources/treebanks/\")\n",
    "):\n",
    "    LIA_path = dir_path / \"Norwegian-NynorskLIA\"\n",
    "    LIA_old_path = dir_path / \"Norwegian-NynorskLIA_old\"\n",
    "    filename = filestem + \".conll\"\n",
    "\n",
    "    lia_file = LIA_path / filename\n",
    "    try:\n",
    "        lia_data = lia_file.read_text()\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            lia_file = LIA_old_path / filename\n",
    "            lia_data = lia_file.read_text()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Couldn't load {filestem}\")\n",
    "            lia_data = \"\"\n",
    "    finally:\n",
    "        lia_sentences = parse(lia_data)\n",
    "    return lia_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = \"test\"\n",
    "(UD_sentences := load_partition(UD_path, partition))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff30b8",
   "metadata": {},
   "source": [
    "# Mapping \n",
    "Iterate over UD sentences and map them to the corresponding LIA sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ba62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ud_partition_to_lia_sentences(sentences: conllu.models.TokenList) -> dict:\n",
    "    mapping = {}\n",
    "    no_match = {}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sent_id = sentence.metadata[\"sent_id\"]\n",
    "        UD_text = sentence.metadata[\"text\"]\n",
    "        filestem = sentence.metadata[\"speakerid\"]\n",
    "        lia_sentences = load_lia_sentences(filestem)\n",
    "        for sent in lia_sentences:\n",
    "            LIA_text = sent.metadata[\"text\"]\n",
    "            if (LIA_text == UD_text) or (LIA_text == UD_text.rstrip(\" .\")):\n",
    "                mapping[sent_id] = sent\n",
    "\n",
    "        if sent_id not in mapping:\n",
    "            no_match[sent_id] = sentence\n",
    "\n",
    "    return {\"match\": mapping, \"no_match\": no_match}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = map_ud_partition_to_lia_sentences(UD_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62b9a56",
   "metadata": {},
   "source": [
    "# Annotate the partition with correct sent_ids and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad338e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lia_partition = []\n",
    "for sent_id, sentence in mapping[\"match\"].items():\n",
    "    sentence.metadata[\"sent_id\"] = sent_id\n",
    "    lia_partition.append(sentence)\n",
    "\n",
    "# Save to disk\n",
    "with open(f\"../data/lia_{partition}.conllu\", \"w\") as f:\n",
    "    f.writelines([sentence.serialize() + \"\\n\" for sentence in lia_partition])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a5b52",
   "metadata": {},
   "source": [
    "## Handle mis-matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97670194",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_match = mapping[\"no_match\"]\n",
    "print(f\"No LIA sentence was found for {len(no_match)} UD {partition} sent_ids.\")\n",
    "\n",
    "fname = f\"no_match_{partition}.txt\"\n",
    "with open(fname, \"w\") as f:\n",
    "    f.writelines(\"\\n\".join(no_match.keys()) + \"\\n\")\n",
    "\n",
    "print(f'They have been saved to \"{fname}\" for later processing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grew_ndt2ud-3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
