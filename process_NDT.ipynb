{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "from udapi.block.ud.setspaceafterfromtext import SetSpaceAfterFromText\n",
    "from udapi.block.ud.fixpunct import FixPunct\n",
    "from udapi.core.document import Document\n",
    "\n",
    "import utils.extract_errorlines as err\n",
    "import utils.convert_morph as conv\n",
    "import utils.parse_conllu as parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KONFIGURER PARAMETERE HER\n",
    "\n",
    "# Språk og partisjon\n",
    "partition = \"dev\"  # \"test\" # \"train\"\n",
    "lang = \"nb\"  # \"nn\"\n",
    "language = \"bokmaal\" if lang == \"nb\" else \"nynorsk\"\n",
    "\n",
    "\n",
    "# Filstier\n",
    "ndt_file=f\"data/ndt_aligned_with_ud/ndt_{lang}_{partition}.conllu\"\n",
    "ud_output_file=f\"data/converted/no_{language}-ud-{partition}.conllu\"\n",
    "ud_official_file=f\"data/UD_official/no_{language}-ud-{partition}.conllu\"\n",
    "report_file = f\"validation-report_ndt2ud_{lang}_{partition}.txt\"\n",
    "\n",
    "# Opprett en mappe for midlertidige filer\n",
    "tmpdir = Path(\"tmp\")\n",
    "tmpdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Morfologiske trekk\n",
    "NDT har sine egne ordklasser (POS-tags) og morfologiske trekk (feats), som må konverteres til UDs tags og feats før vi kan bruke `Grew`. \n",
    "\n",
    "* Modulen `convert_morph.py` konverterer NDTs morfologiske annotasjoner til UD-annotasjoner.\n",
    "* `udapi` har funksjoner for å annotere `SpaceAfter=No` i `MISC`-feltet (`SetSpaceAfterFromText`), som sikrer rett detokenisering når `# text`-kommentaren ikke er tilgjengelig, og for å fikse tegnsetting (`FixPunct`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konverter morfologiske trekk for alle splittene av retokenisert ndt data\n",
    "\n",
    "# for partition in [\"train\", \"test\", \"dev\"]:\n",
    "#    for lang in [\"nb\", \"nn\"]:\n",
    "# input_file = Path(f\"data/ndt_aligned_with_ud/ndt_{lang}_{partition}.conllu\")\n",
    "\n",
    "input_file = ndt_file\n",
    "data = parser.parse_conll_file(Path(input_file))  # Last inn data\n",
    "\n",
    "morphdata = conv.convert_morphology(data)  # Konverter NDT sine UPOS og FEATS til UD-standard\n",
    "\n",
    "tmpfile1 = str(tmpdir / \"01_convert_morph_output.conllu\")\n",
    "parser.write_conll(morphdata, tmpfile1, add_comments=True)  # Skriv CONLL-data til disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legg til SpaceAfter=No i MISC-feltet\n",
    "doc = Document(tmpfile1)\n",
    "\n",
    "processor = SetSpaceAfterFromText()\n",
    "processor.process_document(doc)\n",
    "\n",
    "# output_file = input_file.parent / f\"{input_file.stem}_udmorph{input_file.suffix}\"\n",
    "tmpfile2 = str(tmpdir / \"02_udapy_spaceafter.conllu\")\n",
    "doc.store_conllu(tmpfile2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dependensrelasjoner \n",
    "\n",
    "NDT har andre retningslinjer enn UD, slik at vi må oversette og flytte eller reversere noen dependensrelasjoner.\n",
    "\n",
    "Vi bruker [`Grew`](https://grew.fr/) for å konvertere fra NDT til UD. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%                                                                                             \n"
     ]
    }
   ],
   "source": [
    "tmpfile3 = str(tmpdir / \"03_grew_transform_deprels.conllu\")\n",
    "\n",
    "!grew transform \\\n",
    "    -i  $tmpfile2 \\\n",
    "    -o  $tmpfile3 \\\n",
    "    -grs  \"rules/NDT_to_UD.grs\" \\\n",
    "    -strat \"main_\"$lang \\\n",
    "    -safe_commands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fiks feil som introduseres underveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix punctuation\n",
    "doc = Document(tmpfile3)\n",
    "\n",
    "processor = FixPunct()\n",
    "processor.process_document(doc)\n",
    "\n",
    "tmpfile4  = str(tmpdir / \"04_udapy_fixpunct.conllu\")\n",
    "doc.store_conllu(tmpfile4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile5 = tmpdir / \"05_grew_transform_postfix.conllu\"\n",
    "\n",
    "!grew transform \\\n",
    "    -i $tmpfile4 \\\n",
    "    -o $tmpfile5 \\\n",
    "    -grs rules/NDT_to_UD.grs \\\n",
    "    -strat \"postprocess\" \\\n",
    "    -safe_commands\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove comment line with column names and replace invalid newpar lines\n",
    "text = tmpfile5.read_text()\n",
    "\n",
    "text = re.sub(r\"\\#  = \\# newpar\", \"# newpar\", text)\n",
    "text = re.sub(r\"\\# global.columns = ID FORM LEMMA UPOS XPOS FEATS HEAD DEPREL DEPS MISC\", \"\", text)\n",
    "\n",
    "doc = Document()\n",
    "doc.from_conllu_string(text)\n",
    "doc.store_conllu(ud_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDs eget repo tools har et python-skript som må kjøres \"fra kommandolinjen\"\n",
    "command = [\n",
    "    \"python\",\n",
    "    \"tools/validate.py\",\n",
    "    \"--max-err\",\n",
    "    \"0\",\n",
    "    \"--lang\",\n",
    "    \"no\",\n",
    "    ud_output_file,\n",
    "]\n",
    "\n",
    "# Run the command and capture the output\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "Path(report_file).write_text(result.stderr)\n",
    "\n",
    "\n",
    "# Oppsummering av valideringsrapporten\n",
    "err.report_errors(report_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove comments from the output file and the official UD file so MaltEval can read them\n",
    "tmpfile7 = tmpdir / \"07_remove_comments.conllu\"\n",
    "\n",
    "parser.write_conll(\n",
    "    parser.parse_conll_file(Path(ud_output_file)),\n",
    "    Path(tmpfile7),\n",
    "    add_comments=False\n",
    ")\n",
    "\n",
    "\n",
    "maltgold = tmpdir / \"malt_ud_official.conllu\"\n",
    "\n",
    "parser.write_conll(\n",
    "    parser.parse_conll_file(Path(ud_official_file)),\n",
    "    Path(maltgold),\n",
    "    add_comments=False\n",
    ")\n",
    "\n",
    "# Kjør MaltEval for å sammenligne UD og den konverterte filen visuelt\n",
    "!java -jar dist-20141005/lib/MaltEval.jar -g $maltgold -s $tmpfile7 -v 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KODEDUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDFILE=ndt_file\n",
    "\n",
    "# Fix punctuation\n",
    "!cat $UDFILE | udapy -s ud.FixPunct > out.conllu\n",
    "\n",
    "!cat $UDFILE | udapy -TM \\\n",
    "    util.Mark node='node.lemma == \"som\"' > som.txt\n",
    "\n",
    "!udapy -HMAC \\\n",
    "    read.Conllu zone=old files=$UDFILE \\\n",
    "    read.Conllu zone=new files=out.conllu \\\n",
    "    util.MarkDiff gold_zone=old attributes='form,lemma,upos,xpos,deprel,feats,misc' add=True > diff.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partisjoner data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partisjoner data i dev, train, og test-splittene som UD er delt inn i\n",
    "\n",
    "partitions = {\n",
    "    \"test\" : \"data/test_ids.txt\",\n",
    "    \"dev\" : \"data/dev_ids.txt\",\n",
    "    \"train\" : \"data/train_ids.txt\",\n",
    "}\n",
    "\n",
    "def partition_file(filepath):\n",
    "    fpath = Path(filepath)\n",
    "    for part, idfile in partitions.items():\n",
    "        outputfile = (fpath.parent / f\"{fpath.stem}_{part}{fpath.suffix}\")\n",
    "        part_ids =  parser.filereadlines(idfile)\n",
    "        part_df = df[df.sent_id.isin(part_ids)]\n",
    "        parser.write_df_to_conll(part_df, outputfile, add_comments=True)\n",
    "\n",
    "partition_file(\"data/gullkorpus/2023_gullkorpus_ud.conllu\")\n",
    "partition_file(\"data/gullkorpus/2019_gullkorpus_ud_før_annotasjon.conllu\")\n",
    "partition_file(\"data/gullkorpus/2019_gullkorpus_ndt.conllu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hent eksempelsetninger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.parse_conllu import extract_partition\n",
    "\n",
    "\n",
    "def fetch_conllu_sents(conllu_file, outputfile, sent_ids):\n",
    "    data = parser.load_conll_to_df(\n",
    "        parser.parse_conll_file(conllu_file)\n",
    "    )\n",
    "    sents = data[data.sent_id.isin(sent_ids)]\n",
    "    parser.write_df_to_conll(\n",
    "        sents, outputfile, add_comments=True)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hent ut setningene som gir spesifikke feilmeldinger\n",
    "\n",
    "fpath = Path(\"validation-report_ndt2ud.txt\")\n",
    "etype = \"rel-upos-punct\"\n",
    "save_errorlines = False\n",
    "\n",
    "rows = Path(fpath).read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "error_info_regx = re.compile(r\"^\\[Line (\\d+)(?: Sent )?(\\d+)?(?: Node )?(\\d+)?\\]\\: \\[(L.*)\\] (.*)(\\[[0-9]*, [0-9]*\\])?(.*)?$\", flags=re.DOTALL)\n",
    "errors = []\n",
    "for row in rows:\n",
    "    m = error_info_regx.fullmatch(row)\n",
    "    if m is not None:\n",
    "        errors.append(m.groups())\n",
    "\n",
    "df = pd.DataFrame(errors, columns=[\"line\", \"sent\",\"node\", \"errortype\", \"message\", \"relevant_nodes\", \"message2\"])\n",
    "\n",
    "type_counts = df.errortype.value_counts()\n",
    "print(type_counts)\n",
    "\n",
    "if save_errorlines:\n",
    "    errorlines = df[df.errortype.str.contains(etype)]\n",
    "    errorlines.to_csv(f\"error_{etype}.csv\", index=False)\n",
    "\n",
    "    ndt_file = \"data/ndt_nb_train.conllu\"\n",
    "    outfile = f\"error_{etype}_sents.conllu\"\n",
    "    error_sents = fetch_conllu_sents(ndt_file, outfile, sent_ids=errorlines[\"sent\"])\n",
    "    error_sents.sent_id.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"pattern_matches.json\"\n",
    "\n",
    "with open(filename) as fp:\n",
    "    matches = json.load(fp)\n",
    "\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sents = {s[\"sent_id\"] for s in matches}\n",
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = fetch_conllu_sents(\"data/ndt_nb_dev.conllu\", \"data/sentences/matched_sentences.conllu\", sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
